###  让代码不报错
* 在 tutorial04 的基础上，加上： `#include <libavutil/time.h>`

### 读 tutorial05 可以暂且认为所有视频文件都是按照解码顺序存储packet的

* 是否因为B帧的存在，才导致 `avcodec_decode_video2()` 有可能解不出来一个完整的frame？
* 先看 Tutorial05 的原文：

		B frames are the same as P frames, but depend upon information found in frames that are displayed both before and after them! 
		This explains why we might not have a finished frame after we call avcodec_decode_video2.

* 测试了40个各种格式的视频，没有一个是DTS乱序的，即读出来的 `packet.dts` 永远是递增的
* 所以不存在送给 `avcodec_decode_video2()` 的 packet 因为需要参考尚未读出来的 packet 所以解码不出来的情况，起码对这40个文件如此。
* 有些 video packet 确实解码不出来数据
* 看了这40个文件每一个 video packet 送给 `avcodec_decode_video2()` 之后，是否真的解码出来了图像，看的是 `avcodec_decode_video2()` 的第三个参数。
* 第三个参数的意义： Zero if no frame could be decompressed, otherwise, it is nonzero.
* 这40个文件里，绝大多数解不出来图像的packet是文件最开始的几个packet(1~6个)，只有一个在文件中间还有这样的packet的情况。
	* 为什么文件最开始的几个packet那么容易解不出来图像？——这个貌似跟codec相关，h264的必然前4~6帧解不出来，MPEG1、MPEG2的第一帧解不出来，h263则都能解出来。
	* 那个在文件中间部分仍然有解不出来图像的文件是否是一些损坏了的文件？ ——貌似是未授权的编码器给加密了，播放该文件时屏幕上有大大的水印：“created with a non-activated version www.avs4you.com”
* 不过这40个文件里有很多PTS是乱序的，这是很正常的，有B帧的情况下，DTS和PTS不相等很正常，有些先解码出来的需要后显示。
* 起码基于这40个文件的测试结果，Tutorial05 里说的：因为B帧的原因，所以 `avcodec_decode_video2()` 有可能解不出来一个完整的frame，是不成立的。
* 解码不出来图像可能有多种原因，其中一个可能是读packet的函数读到的packet并不是真正的视频数据：

		 * This function returns what is stored in the file, and does not validate
		 * that what is there are valid frames for the decoder. It will split what is
		 * stored in the file into frames and return one for each call. It will not
		 * omit invalid data between valid frames so as to give the decoder the maximum
		 * information possible for decoding.

### time base
* time base 是一个以秒为单位的分数，比如 1/44100 秒。
* FFmpeg 里的 `time_base` 是用结构体 `AVRational` 表示的。
* AVRational：

		:::c
		typedef struct AVRational{
		    int num; // 分子
		    int den; // 分母
		} AVRational;

* FFmpeg 提供了一个函数把 AVRational 转换成 double：`double av_q2d(AVRational a)`
* pts，dts 以 time base 为单位。
* 比如 `time_base=1/11776`秒，则 pts = 3260, 则表示 `pts = 3260 * 1/11776` 秒
* 每一个 stream 有一个 time base。比如 audio stream 的 time base 可能等于这条音频流的 sample rate。video stream 的 time base 可能等于这条视频流的 frame rate（一般不等于）。

### packet 的 pts 不等于 frame 的 pts
* 对于视频流来说，一个 packet 解码成一个 frame，所以我们自然的认为 packet 的 pts 一定等于解码出来的 frame 的 pts。但事实不是这样。
* 看一下 AVPacket 里对于 pts 和 dts 的定义：

		:::c
	    /**
	     * Presentation timestamp in AVStream->time_base units; the time at which
	     * the decompressed packet will be presented to the user.
	     * Can be AV_NOPTS_VALUE if it is not stored in the file.
	     * pts MUST be larger or equal to dts as presentation cannot happen before
	     * decompression, unless one wants to view hex dumps. Some formats misuse
	     * the terms dts and pts/cts to mean something different. Such timestamps
	     * must be converted to true pts/dts before they are stored in AVPacket.
	     */
	    int64_t pts;
	    /**
	     * Decompression timestamp in AVStream->time_base units; the time at which
	     * the packet is decompressed.
	     * Can be AV_NOPTS_VALUE if it is not stored in the file.
	     */
	    int64_t dts;

* 再看一下 AVFrame 里对于 pts 和 dts 的定义：

		:::c
	    /**
	     * Presentation timestamp in time_base units (time when frame should be shown to user).
	     */
	    int64_t pts;
	
	    /**
	     * PTS copied from the AVPacket that was decoded to produce this frame.
	     */
	    int64_t pkt_pts;
	
	    /**
	     * DTS copied from the AVPacket that triggered returning this frame. (if frame threading isn't used)
	     * This is also the Presentation time of this AVFrame calculated from
	     * only AVPacket.dts values without pts values.
	     */
	    int64_t pkt_dts;

	* Frame 里就没有 dts 了，因为 frame 不需要再解码了。
	* Frame 里用 `pkt_dts` 和 `pkt_pts` 来存储对应 packet 里的 dts 和 pts
	* Frame 有自己的 pts，一般来说是不等于 packet 的 pts 的

* packet 的 pts 是 demuxer 从文件里读出来的，frame 的 pts 是由解码器在解码这一帧时设定的。他们两个有时候可能会有些小偏差，但根据测试，差的不多。
* 我们还是要以 frame 的 pts 为准。
* AVFrame 提供了一个成员来更加准确的表示一个 frame 的 pts：`best_effort_timestamp`
* 看 AVFrame 里对这个成员的定义注释：

		:::c
	    /**
	     * frame timestamp estimated using various heuristics, in stream time base
	     * Code outside libavcodec should access this field using:
	     * av_frame_get_best_effort_timestamp(frame)
	     * - encoding: unused
	     * - decoding: set by libavcodec, read by user.
	     */
	    int64_t best_effort_timestamp;

* 这个成员变量无法直接访问，必须通过函数`av_frame_get_best_effort_timestamp` 来得到。
* Frame 的 pts 和 `best_effort_timestamp` 这两个成员变量，`best_effort_timestamp` 是比较准的。测了几个mp4（h164），rmvb，wmv，他们的视频 frame.pts 永远等于0。
* ffplay 里面是这样使用 video frame 的 pts：
	* 解码到frame里之后，frame.pts 由用户（ffplay）设定
	* 正常情况下，设为 `av_frame_get_best_effort_timestamp(frame);`
	* 特殊情况下，设为 `frame->pkt_pts;`


### `AVStream.time_base` 和 `AVCodecContext.time_base`
* 每个 stream 对应一个自己的 CodecContext，但 stream 本身有一个 `time_base`，它的 CodecContext 也有一个 `time_base`
* 看 AVCodecContext 里 time base 的定义：

		:::c
	    /**
	     * This is the fundamental unit of time (in seconds) in terms
	     * of which frame timestamps are represented. For fixed-fps content,
	     * timebase should be 1/framerate and timestamp increments should be
	     * identically 1.
	     * This often, but not always is the inverse of the frame rate or field rate
	     * for video.
	     * - encoding: MUST be set by user.
	     * - decoding: the use of this field for decoding is deprecated.
	     *             Use framerate instead.
	     */
	    AVRational time_base;

* 看 AVStream 里 time base 的定义：

		:::c
	    /**
	     * This is the fundamental unit of time (in seconds) in terms
	     * of which frame timestamps are represented.
	     *
	     * decoding: set by libavformat
	     * encoding: May be set by the caller before avformat_write_header() to
	     *           provide a hint to the muxer about the desired timebase. In
	     *           avformat_write_header(), the muxer will overwrite this field
	     *           with the timebase that will actually be used for the timestamps
	     *           written into the file (which may or may not be related to the
	     *           user-provided one, depending on the format).
	     */
	    AVRational time_base;

* 从定义看，也没看出来区别。
* 测试了很多文件，有的文件是相等的，有的不相等。有的不相等的差2倍，有的则差了好几千倍。
* 再看 packet 的 pts 和 frame 的 pts 的定义，你会发现：
	* packet 的 pts **以 AVStream 的 time base 为单位**（in `AVStream->time_base`，）

			:::c
			Presentation timestamp in AVStream->time_base units
		
	* frame 的 `best_effort_timestamp` **以 AVStream 的 time base 为单位**（in `stream time base`）

			:::c
			frame timestamp estimated using various heuristics, in stream time base
	
	* frame 的 pts （本程序中没有使用） **以 AVCodecContext 的 time base 为单位**（没明说，应该是这个意思）

			:::c	
			Presentation timestamp in time_base units (time when frame should be shown to user).

* 总之你要知道，pts、dts 都是一个数，但这个数以什么为单位还不知道。是以1/10秒为单位呢，还是以1/3000秒为单位呢？
* 是以 time base 为单位的。但以哪个 time base 为单位呢？有的 pts 是以 AVStream 的 time base 为单位，有的是以 AVCodecContext 的 time base 为单位。
* 知道了 pts、dts 之后，还要知道它的单位，才能换算成秒。
* 换算成秒之后的 pts，就相当于播放器进度条上的一个点（position）。比如一帧的 pts 是 123365秒，说明这一帧该在进度条的第 123365秒显示。


### `AV_NOPTS_VALUE`
* 看看 `AV_NOPTS_VALUE` 的注释：

		:::c
		/**
		 * @brief Undefined timestamp value
		 *
		 * Usually reported by demuxer that work on containers that do not provide
		 * either pts or dts.
		 */

### `int64_t av_frame_get_best_effort_timestamp(const AVFrame *frame);` 函数的实现
* 这个函数是通过宏定义的，直接搜关键字 `av_frame_get_best_effort_timestamp` 搜不到函数的实现
* 在 `libavutil\frame.h` 定义了这个函数的原型： `int64_t av_frame_get_best_effort_timestamp(const AVFrame *frame);`
* 在 `libavutil\internal.h` 有： `#define MAKE_ACCESSORS(str, name, type, field) type av_##name##_get_##field(const str *s) { return s->field; } `
* 在 `libavutil\frame.h` 有： `MAKE_ACCESSORS(AVFrame, frame, int64_t, best_effort_timestamp)` ，这个带参数的宏被展开为：
* `int64_t av_frame_get_best_effort_timestamp(const AVFrame *s) { return s->best_effort_timestamp; } ` 
* 说白了，`av_frame_get_best_effort_timestamp(const AVFrame *frame)` 只是简单的返回了 frame 的成员变量 `best_effort_timestamp`
* 只不过这个成员变量对于 ABI 来说是不可见的，只能通过以上函数来得到。

### 根据 framerate 决定播放视频的速度（05.01）

##### 以下几个地方都能获取framerate：
* `AVCodecContext.framerate`
* `AVStream.r_frame_rate`
* `AVStream.avg_frame_rate`

##### 用以下 ffmpeg 提供的函数是更好的选择：
* `av_guess_frame_rate`
	* 原型： `AVRational av_guess_frame_rate(AVFormatContext *ctx, AVStream *stream, AVFrame *frame); `
	* 第三个参数 AVFrame 可以传 NULL， ffplay 就是这么干的

#### 最好的方法还是用 pts 控制速度以及音视频同步
* 有些文件获取不到 framerate，
* 有可变帧率的文件

### 音视频同步（05.02）

### 如果不考虑音视频同步，视频怎么播
* 在显示一副画面之前，计算delay： delay = 当前画面的pts - 前一副画面的pts。
* 测试了10个不同格式的文件，平均有百分之20到百分之45的视频帧，其pts==前一帧的pts。
* 20%~45%，这个比例不少，所以我们必须处理这种情况。
	* 如果 delay 等于 0，则让 delay = 0.01 。
* 延迟 delay 秒，再显示。 

### 如果不考虑音视频同步，音频怎么播
* 音频设备按照freq（sample rate）去播，每当播完了，就调用回调函数要数据
* 回调函数去packet队列里拿出一定数量的packet（可能是1个，不到1个，多于1个），解码出一定的数据，送给音频设备继续播。
* 音频播放没有考虑pts，就是一直在播。

### 如何音视频同步

##### 维护音频 pts： `is->audio_clock`
* 虽然音频一直往前播，不考虑pts。但是为了音视频同步，所以需要维护一份音频的 pts，好让视频知道音频播到第几秒了。
* `is->audio_clock` 表示目前音频播放到了第几秒。
* 每当音频回调函数取出一个 pkt，就把当前 pkt 的 pts（乘以 time base 转换成秒的）赋给 `is->audio_clock`。
* 如果这个 pkt 解码出了一定的音频数据，则再把这些音频数据能播放的秒数加到 `is->audio_clock` 上。

##### 用视频去跟音频同步
* 在播放视频的时候，如果不考虑跟音频同步，只需要 delay （当前画面的pts - 前一副画面的pts）即可。
* 现在考虑跟音频同步，则先计算一下当前视频的pts和音频的pts差多少。
* 如果视频的pts比音频的pts小很多，说明视频慢了，此时我们把 delay 设为0，让视频尽可能快的播。
* 如果视频的pts比音频的pts大很多，说明视频快了，此时我们把 delay 设为2*delay，让视频慢下来。
* 这里的“很多”被写死成了 0.01 秒。