### 解码
####  函数原型 

        int avcodec_decode_video2	(	AVCodecContext * 	avctx,
            							AVFrame * 	picture,
            							int * 	got_picture_ptr,
            							const AVPacket * 	avpkt 
            						)
    
* 把 avpkt 里的数据解码，解出来的 frame 存入 picture
* The codec will allocate memory for the actual bitmap，即这里的输出参数 picture 不用提前分配好 buffer，这个函数会为他分配。

### 解码之前，用 codec 初始化 codec context

#### 函数原型 

        int avcodec_open2	(  AVCodecContext * 	avctx,
				        const AVCodec * 	codec,
						AVDictionary ** 	options 
					 )	
					 
* 这个函数的作用是根据 codec 去初始化 codecContext：Initialize the AVCodecContext to use the given AVCodec.  
* 而 codecContex 需要提前分配好，用 avcodec_alloc_context3()：Prior to using this function the context has to be allocated with avcodec_alloc_context3().   
* 在开始真正的解码之前必须要调用这个函数来初始化 codecContext：Always call this function before using decoding routines (such as avcodec_decode_video2()).   
* 参数：
	* avctx：	The context to initialize.
	* codec：	The codec to open this context for.
	* options： codec 的私有选项，一般不用设，传NULL即ZSL总司令212
	可。
	
	

### AVPicture结构体：图像数据的表示

* 像素数据存放在 data[4] 里面
    * 对于 YUV420 的图像，data[0] 存Y，data[1] 存U，data[2] 存V
    * 对于 RGB24 的图像，data[0] 存 rgb，data[1]~data[3] 没有意义
    * 其他格式的图像数据有其他的存法
    * 总之 data 是一个存放指针的数组，data[0]~data[3] 都是指针，各自指向一片像素数据区

* 还需一个额外的 linesize[4] 来表示
    * 比如 RGB24 的图像，data[0] 指向了一大片内存，里面全是二进制数据，表示一整副图像。
    * 那么 linesize[0] 就表示了多少个字节之后，就是图像的下一行了。
    * YUV 同理。

* linesize 不一定等于图像的宽度：padding
    * 每一行像素的结尾处有一个 padding，linesize=图像宽度+padding
    * 不同格式的图像，padding 值不同，比如 RGB24 的 padding 是
    * padding 是为了做复杂的编解码运算时提高速度，比如做运动补偿啥的，具体的也不了解，也不用了解。
    * padding 的值是有公式的：RGB 的 padding = ， YUV 的 padding = 
    * 所以说知道了 pix_format 之后，是可以根据图像宽度换算出 linesize 的
    * 不过 AVPicture 结构体里，只有 data 和 linesize 两个成员，没有描述图像宽度和 pix_format 的成员

### AVFrame结构体：结构体本身
* 初始化
* 填充
