###需要先看一下 SDL 播放音频数据的基础
* 参考： [http://blog.csdn.net/leixiaohua1020/article/details/40544521](http://blog.csdn.net/leixiaohua1020/article/details/40544521)
* 这个源码里也要加上（在所有include之后） #undef main
* 简化（去掉了循环播放，用 memcpy 代替了 SDLMix ）后的代码如下：

		:::c
		#include <SDL.h>
		#include <SDL_thread.h>
		
		#include <stdio.h>
		#include <tchar.h>
		
		#undef main 
		
		static  Uint8  *audio_chunk;
		static  Uint32  audio_len;
		static  Uint8  *audio_pos;
		
		/* Audio Callback
		* The audio function callback takes the following parameters:
		* stream: A pointer to the audio buffer to be filled
		* len: The length (in bytes) of the audio buffer
		*
		*/
		void  fill_audio(void *udata, Uint8 *stream, int len) {
			if (audio_len == 0)
				return;
			len = (len>audio_len ? audio_len : len);
		
			memcpy(stream, audio_pos, len);
			audio_pos += len;
			audio_len -= len;
		}
		
		int main(int argc, char* argv[])
		{
			//Init
			if (SDL_Init(SDL_INIT_AUDIO | SDL_INIT_TIMER)) {
				printf("Could not initialize SDL - %s\n", SDL_GetError());
				return -1;
			}
			//SDL_AudioSpec
			SDL_AudioSpec wanted_spec;
			wanted_spec.freq = 44100;
			wanted_spec.format = AUDIO_S16SYS;
			wanted_spec.channels = 2;
			wanted_spec.silence = 0;
			wanted_spec.samples = 1024;
			wanted_spec.callback = fill_audio;
		
			if (SDL_OpenAudio(&wanted_spec, NULL)<0) {
				printf("can't open audio.\n");
				return -1;
			}
		
			FILE *fp = fopen("D:\\CppWorkSpace\\FFmpegTutorial\\x64\\Debug\\chimei_416x240_42sec.pcm", "rb+");
			if (fp == NULL) {
				printf("cannot open this file\n");
				return -1;
			}
			int pcm_buffer_size = 4096;
			char *pcm_buffer = (char *)malloc(pcm_buffer_size);
		
			//Play
			SDL_PauseAudio(0);
		
			while (fread(pcm_buffer, 1, pcm_buffer_size, fp)) {
				//Set audio buffer (PCM data)
				audio_chunk = (Uint8 *)pcm_buffer;
				//Audio buffer length
				audio_len = pcm_buffer_size;
				audio_pos = audio_chunk;
				while (audio_len>0)//Wait until finish
					SDL_Delay(1);
			}
			free(pcm_buffer);
			SDL_Quit();
		
			return 0;
		}

* 注：代码中用到的pcm音频文件可以用ffmpeg.exe生成：`ffmpeg -i input.mp4 -vn -f s16le -ar 44100 -acodec pcm_s16le output.pcm`

#### SDL 播放音频
* `SDL_OpenAudio()` 会打开音频设备，打开之后并没有开始播放
* `SDL_PauseAudio()` 会让音频设备开始播放音频 
* 音频设备播放音频： 
	* 当音频设备觉得该播放下一段了，会调用一个回调函数，让回调函数送数据过来。所以回调函数有个参数是音频设备缓冲区的地址，让回调函数往里写音频数据的，当然还有一个参数告诉你我需要多大的数据，你别写多了。
	* 所以回调函数就干一件事儿就行了：给缓冲区写数据。比如用 `memcpy()`。
	* 音频设备播放缓冲区里的数据时，是按照打开音频设备时（`SDL_OpenAudio()`）设定的参数播的：比如你设定了采样率是 44100，那么它就每秒播放 44100 个采样。比如你设定了采样格式是“signed 16bit 小端存储”，那么音频设备就按每个采样16bit去读取并播放。
	* 当音频设备觉得缓冲区的数据播完了的时候，它自然就去调用回调函数要数据了。
	* 另外回调函数还有一个参数用来存放用户信息。

### Tutorial03

#### 题外话
* 为了产生一个 tutorial3 代码能正常播放声音的文件，必须生成音频的 `sample_fmt` 是 s16 的
* `ffmpeg -sample_fmts` 可以查看所有支持的采样格式
* 尝试尽了各种组合，比如： `ffmpeg -i input.mp4 -vcodec h264 -ar 44100 -acodec mp2 -sample_fmt s16 out.mp4`
* 但要么转不出来，要么转出来的文件音频格式不是 s16（用 ffprobe 看，上述命令的音频采样格式是 s16p，多了个p，差别千里）

#### 修改代码以便能运行

* 改了一行报错的代码，加了强转：

		:::c
		pkt1 = (AVPacketList *)av_malloc(sizeof(AVPacketList));

* 音频的基本知识看 tutorial 的讲解就可以了

#### PCM 的格式

* 代码里有这么一句

		:::c
		wanted_spec.format = AUDIO_S16SYS;

* tutorial 的解释是： `This is the format that avcodec_decode_audio2 will give us the audio in.`
* 但是查 `avcodec_decode_audio2`（其实是 `avcodec_decode_audio4`）的文档没有说解码完的音频是什么格式
* 其实解码成什么格式，是从 CodecContext 里读到的，（跟解码视频一样，视频的 `pix_fmt` 从 CodecContext 里读来)
* 就是说，对音视频进行编码的时候，就说好了解码出来是什么格式的音/视频
* 视频格式有 yuv420p，yuv422 等等很多种，音频也一样。 音频有 `unsigned 8 bits`，`signed 16 bits, planar` 等等。
* 音频未压缩的原始数据是以‘采样（Sample）’为单元的，就类似于图像数据的帧。`unsigned 8 bits` 就表示一个采样用 8 bit 无符号数据来表示。
* ffmpeg 的音频采样格式封装在枚举`enum AVSampleFormat`里
* 在 `AVCodecContext` 里，用字段 `enum AVSampleFormat sample_fmt` 来表示音频数据的采样格式。
* 所以以上代码，精确的写法应该类似这样：

		:::c
		switch (aCodecCtx->sample_fmt)
		{
		case AV_SAMPLE_FMT_S16:
			wanted_spec.format = AUDIO_S16SYS;
			break;
		case AV_SAMPLE_FMT_U8:
			wanted_spec.format = AUDIO_U8;
			break;
		default:
			wanted_spec.format = AUDIO_S16SYS;
			break;
		}

* SDL 和 ffmpeg 对原始音频数据的封装还是有很大区别：ffmpeg 里定义了 8 bit，16 bit，32 bit，有无符号，浮点型，Double 型，是否 Planar 存储等10多种音频采样格式，而 SDL 只定义了 8 bit，16 bit，有无符号，大小端存储等6种。

	* ffmpeg 不区分大小端存储，统一使用跟系统相同的字节序：`The data described by the sample format is always in native-endian order.`
	* SDL 可以手动区分大小端存储：`AUDIO_U16LSB` 16 bit unsigned 小端存储。`AUDIO_S16MSB`16 bit unsigned 大端存储。
	* SDL 用后缀 LSB 表示小端存储，MSB 表示大端存储，SYS 表示跟系统一致（native byte ordering）

* 总之要把 ffmpeg 解码出来的原始音频数据 map 到 SDL 能处理的格式。 视频也是一样的。
* 不过基于以上说的，他俩表示音频格式的方法差别较大，所以几乎没办法一一对应的 map。能一一对应的，也就上面代码里的那两种。
* 如果（现实中应该是经常）遇到 ffmpeg 解出来而 SDL 不支持的格式，我们还要想别的办法，比如重采样（类似于视频的 swscale，本文后续会讲）什么的。
* 因为 tutorial03 的代码，强制把 `wanted_spec.format` 设置成了 `AUDIO_S16SYS`，所以 SDL 在播放音频的时候，就按照 signed 16 bit native-order 来播。
* 但是，如果你打开的音频不是这种格式的，你就会听到奇怪的声音。比如我测试的时候从网上下载了个mp4，用ffprobe看的时候，其音频流的采样格式为 fltp，是一种 32 bit 浮点数表示法，不是 signed 16。
* 所以用 tutorial03 播起来声音全是噪声。

#### 视频会飞快播完，声音正常播放
* tutorial03 的代码播放一个文件，视频会飞快播完，声音正常播放
* 这是 SDL 播放音频和播放视频的机制不同引起的
* 播放视频，是我们主动让它播，我们每解一帧就让他播一帧，所以播的飞快，因为解码飞快
* 而音频，SDL 是自己播的，他按照我们打开音频设备时设置好的采样率、采样格式去播，所以它知道一秒钟该播放多少个采样。当它播完了缓冲区中的所有采样，它主动调回调函数找我们要数据。
* 所以SDL播音频听起来是正常速度。
* 由于视频播完程序就退出了，所以正常速度播放的声音可能没听全就结束了。可以在读packet那个while结束的地方加个 getchar()，这样就能听全整首歌了。

#### ffmpeg 实在是编不出来 s16 格式的音频啊
* `ffmpeg -i chimei_416x240_42sec.mp4 -acodec mp2 -ac 2 -ar 44100 -sample_fmt s16 -vcodec h264  out.mp4`
* 以上命令编码，按理说应该产生的是 `sample_fmt` 为 s16 的音频
* 但是，用 ffprobe 看，结果却是：

    	Stream #0:1(eng): Audio: mp3 (mp4a / 0x6134706D), 44100 Hz, stereo, s16p, 383 kb/s (default)

* 里面的 s16p 代表 `sample_fmt` 是 s16p，而我们命令行参数下的是 s16。说明 ffmpeg 并没有按照 s16 来转，可能是 mp2 这个 codec 不支持 s16 这种采样格式。 试了好多种 audio codec 都是不支持。
* 用代码打开文件，看 audio的 `CodecContext->sample_fmt` ，确实等于6，即 `AV_SAMPLE_FMT_S16P` （而不是1，`AV_SAMPLE_FMT_S16`）


### 格式转： `swr_convert()`

#### channel layout
* 所谓 channel layout，是用一串二进制数表示声道，其中1的个数等于声道数
* 根据 `libavutil/channel_layout.h `开始的注释：

         * A channel layout is a 64-bits integer with a bit set for every channel.
         * The number of bits set must be equal to the number of channels.
         * The value 0 means that the channel layout is not known.
         * @note this data structure is not powerful enough to handle channels
         * combinations that have the same channel multiple times, such as
         * dual-mono.


* 在`libavutil/channel_layout.h ` 里定义了一系列的宏来表示声道layout，比如：

		:::c
        #define AV_CH_FRONT_LEFT             0x00000001
        #define AV_CH_FRONT_RIGHT            0x00000002
        #define AV_CH_FRONT_CENTER           0x00000004

        #define AV_CH_LAYOUT_MONO              (AV_CH_FRONT_CENTER)
        #define AV_CH_LAYOUT_STEREO            (AV_CH_FRONT_LEFT|AV_CH_FRONT_RIGHT)
        #define AV_CH_LAYOUT_5POINT0           (AV_CH_LAYOUT_SURROUND|AV_CH_SIDE_LEFT|AV_CH_SIDE_RIGHT)
        #define AV_CH_LAYOUT_5POINT1           (AV_CH_LAYOUT_5POINT0|AV_CH_LOW_FREQUENCY)

* Channel Layout 能比声道个数更加详细的描述声道信息
* 在ffmpeg里用 `int64_t` 来表示声道layout
* 在 layout 和声道个数之间转换，ffmpeg 也提供了函数：

		:::c
        int av_get_channel_layout_nb_channels(uint64_t channel_layout); // 根据 layout 得到声道个数
        int64_t av_get_default_channel_layout(int nb_channels); // 根据声道个数得到 default layout

#### 格式转换 
* 用 `swr_alloc_set_opts()` 得到一个`SwrContext`

		:::c
        struct SwrContext *swr_alloc_set_opts(struct SwrContext *s,
                                              int64_t out_ch_layout, enum AVSampleFormat out_sample_fmt, int out_sample_rate,
                                              int64_t  in_ch_layout, enum AVSampleFormat  in_sample_fmt, int  in_sample_rate,
                                              int log_offset, void *log_ctx);

* 第一个参数传NULL，则给你生成一个 SwrContext 返回
* 接下来三个参数是设置输出格式的，可以看到，用来描述声道信息的是 layout 而不是 声道个数。
* 再接下三个参数是输入格式。最后两个参数先不用管。
* 用 `swr_init(SwrContext swr_ctx)` 初始化
* 用 `swr_convert()` 进行转换格式

		:::c
        /** Convert audio.
         * 
         * @param s         allocated Swr context, with parameters set
         * @param out       output buffers, only the first one need be set in case of packed audio
         * @param out_count amount of space available for output in samples per channel
         * @param in        input buffers, only the first one need to be set in case of packed audio
         * @param in_count  number of input samples available in one channel
         *      
         * @return number of samples output per channel, negative value on error
         */
        int swr_convert(struct SwrContext *s, uint8_t **out, int out_count,
                                        const uint8_t **in , int in_count);
         

#### ffplay 对 Audio 格式的处理
* 用SDL播放声音，SDL打开音频设备的主要参数:
	* format: 写死了 `wanted_spec.format = AUDIO_S16SYS;`
	* sample rate: 让用户（程序员）设定 `wanted_spec.freq = wanted_sample_rate;`
	* channels: SDL优先，用户设定其次，好几行代码就不贴在这里了，详见 `audio_open` 函数最开始的几行
* 解码出来的音频用 `swr_convert()` 进行转换格式以达到SDL设备要求，输出参数：
	* format： 写死了 `audio_hw_params->fmt = AV_SAMPLE_FMT_S16;`，以便跟SDL对应。
	* sample rate：根据SDL打开音频设备后返回的实际值设定：`audio_hw_params->freq = spec.freq;`
	* channels： 根据SDL打开音频设备后返回的实际值设定： `audio_hw_params->channels =  spec.channels;`
	* channels 稍微复杂，因为还弄了一个 `audio_hw_params->channel_layout = wanted_channel_layout;` 以保证channels的准确性


#### 尽量不要转换 sample rate
* 打开SDL音频设备之前，先读出来当前播放的文件的 sample rate，然后以这个 sample rate 去打开音频设备
* 不要写死打开音频设备时的 sample rate，然后再用 `swr_convert() `去把文件里的 sample rate 转成音频设备的
* 因为改变 sample rate 的转换会失真，听起来有噪声
* 这个问题耽误了我4天时间。。。
