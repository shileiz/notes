## 视频

### 视频：连续的图像
* 所谓视频，就是连续的图像
* 每一张图像称为一帧
* 每秒多少幅图像称为帧率

### “原始”图像：YUV

* 跟GRB类似，是一种描述“原始”图像的色彩空间。Y表示亮度，U、V表示色度。
* 无论RGB还是YUV，都是一个点一个点的描述一幅图像，一张图有多少个点就需要多大的空间来存储这张图。
* 人眼对亮度更敏感，所以可以少用U、V节省空间。占用空间可以由每像素点3个字节，变成2个字节甚至1.5个字节。
* 但无论如何，YUV描述的是“原始”图像，即一个像素占用一定的字节数（3个或者1.5...）。“原始”图像都是非常大的。

### 格式 & 分辨率 & 帧率

* “原始”图像记录的仅仅是像素内容，而没有描述相关信息。只有内容，是无法显示“原始”图像的。
* 格式告诉播放器YUV是怎么存储的。
* 分辨率告诉播放器，每幅图像从哪里开始是下一行。
* 帧率告诉播放器要以多快的速度播放每一幅图像（1帧即一幅图像）。

### 视频的大小
* 总帧数 x 每一帧像素数 x 每个像素字节数
* 总帧数 = 视频时长 x 帧率
* 每一帧像素数 = 分辨率
* 每个像素字节数 = 取决于格式
	* {RGB24 = 3字节，RGB32 = 4字节，YUV444 = 3字节，YUV422 = 2字节，YUV420 = 1.5字节}
	* 注：以上均默认以 8bit 描述一个分量，如果以10bit、12bit、16bit 等描述一个分量，需要进行换算。

### 压缩
* 单张图片（了解即可）
	* 找出点和点之间的关系，用数学方法进行计算，不再一个点一个点的存储，大大节省空间。
	* jpg，png 等常见的图片，都是压缩过的。
* 连续的图片——视频
	* 单张图片可以采取类似的方法压缩。
	* 找出相邻的两张（或者多张）图片的差异，仅仅描述差异即可，更加大大的节省空间 
* I帧、P帧、B帧
	* I帧就是“关键帧”、“KeyFrame”，以它作为标准，后续图片只记录跟它之间的差异。
	* P帧就是紧紧记录了差异量的图片，所以光有P帧是无法表达一张图的，得找到它参考的那个I帧才可以。
	* B帧跟P帧类似，只是B帧不光参考它前面的那个I帧，还参考它后面的I帧（或者P帧）。 
* 现实中的视频都是压缩过的，比如 mp4、rmvb、flv、mkv、wmv等等。
* 压缩过程实际上是复杂的数学运算，不同的数学方法会带来不同的压缩效果。

### codec & format
* 我们把某种压缩的数学方法，称为一种 codec。常见的有：h.264、h.265（hevc）、vp9、realvideo7、8、9，wmv7、8、9 等等。
* codec只是负责压缩，压缩后我们同样需要告诉播放器分辨率、帧率这些信息，播放器才能正确的播放。
* 所以我们在codec压缩过的数据之外又包了一层数据，称之为“封装”。或者叫“mux”，“container”，“复用”，“format”，这些词指的都是这一层。
* 常见的封装格式有： mp4、rmvb、flv、mkv、wmv等等。即我们常见的后缀名。
* 因为 format 层已经记录了分辨率、帧率等信息，所以我们播放封装过的视频文件时，就不需要手动输入了，双击即可播放。（播放器软件去“封装”里读出相应的参数）
* 某种封装格式只能封装特定的几种codec，具体可以去维基百科查，或者查这种格式的文档。

### 码率
* 压缩后的视频大小，不再是简单的换算，因为不再是逐个像素存储视频。
* 用压缩后的视频大小除以视频时长，得到的这个数，我们**称之为**码率。
* 一般来说，同一种codec，码率越大则视频质量越高（压缩过程损失的越少）。
* 不同的codec，如果在视频质量相同的情况下，码率越小，说明他的压缩效果越好。

### 题外话：视频质量
* PSNR、SSIM、VQM 等等
* 原理类似：跟压缩前的“原始”图像比较。数学公式不同。
* 另外就是找人来用眼睛看。不需要数学计算。

### 编码器和播放器
* 摄像头/DV/采集卡等设备（得到原始YUV）---》编码器进行压缩（codec：encode）---》编码器进行封装（format：mux）---》输出.mp4等文件
* mp4等文件---》播放器的解封装组件进行解封装（format：demux）----》播放器的解码组件进行解码，还原出YUV（codec：decode）-----》交给显卡进行显示
* 注1：摄像头/DV/采集卡等硬解设备，只能一个像素一个像素的捕捉图像，得到的是“原始”图像
* 注2：显卡等硬解设备，也只能一个像素一个像素的显示图像，需要的也是“原始”图像
* 注3：filter 先不提

## 音频

### 音频：连续的采样
* 所谓（数字）音频：就是连续的采样（Sample）
* 每秒多少个采样称为采样率，常见的有 44100、48000等

### 原始音频：Sample-format 和 channel
* 用多少个字节，什么字节格式描述一个采样就是所谓的 Sample-format
* 比如可以用1个字节无符号整数来描述一个Sample（u8），也可以用32位浮点数来描述一个Sample（flt） 
* 声道：采样率指的是单个声道每秒钟有多少个采样，如果是2声道，则整个音频每秒的采样数就要乘以2

### 压缩
* 音频的压缩实际上也是一系列的数学运算，把原本比较大的采样压缩成比较小的数据存放。

### codec & format
* 跟视频类似，音频也有codec和format的概念，不再重复叙述。
* 音频常见的codec有：aac，ac3，wma1、2，mp3等等
* 音频常见的封装格式有：mp3、wma等
* “复用”：实际上，“复用”/“mux” 这个词指的是视频和音频共用一个文件来存储，即mp4、flv等format里即放了视频数据也放了音频数据。所以说，“复用” 和 “format” 等词，指的是同一层的东西。

### 码率
* 音频码率跟视频码率类似，不再赘述

## FFmpeg
* 几乎涵盖了音视频处理的各个阶段的各种功能
* 可以把原始视频/音频进行压缩，进行封装，产生 mp4/flv 等常见视频文件
* 也可以把压缩后的 mp4/flv 等文件进行解封装和解压缩，产生出原始像素数据和原始音频采样数据。
* 不包括采集原始视频、音频的功能：这属于摄像机，麦克风等硬件的工作范围
* 也不包括把原始音视频数据显示到屏幕上或者耳机里的功能：这是显卡，声卡等硬件的工作范围

### ffmpeg.exe 
* 解码
	* mp4等文件---》解封装（demux）----》解码（decode）----》YUV原始像素序列文件
	* `ffmpeg -i a.mp4 -vcodec rawvideo a.yuv`
* 编码
	* YUV----》压缩（encode） ----》封装（mux） ---- 》mp4等文件
	* `ffmpeg -s 965x540 -r 24 -i a.yuv -vcodec h264 a.mp4`
* 转码：把一种压缩格式转换成另外一种压缩格式。即把编码和解码两个步骤一次完成。
	* `ffmpeg -i a.mp4 -vcodec h264 -s 320x240 -b:v 500K -acodec mp3 b.mp4` 

### ffprobe.exe

#### stream： 流
* ffmpeg 里用 stream 来表示音频和者视频。
* 一个文件里，既有音频又有视频，把文件里的音频称作音频流，视频称作视频流。
* 一个文件里可能有多条视频流和多条音频流，不一定非得是一个视频一个音频。比如英语、汉语、法语、各自一条音频流。高码率、中码率、低码率各自一条视频流等等。
* 除了音频流和视频流，文件里还可能有字幕流。

#### ffprobe：把文件里的所有stream的信息打印出来
* `ffprobe a.mp4`

### ffplay.exe
* 一个完整的播放器： `ffplay a.mp4`。可以用键盘控制快进快退暂停等。
* 因为ffmpeg本身不负责音频和视频的输出，上文说过，是显卡声卡等负责。所以ffplay借助了其他开源库来实现音视频的最终输出。就是SDL。
* SDL封装了各种各种平台的音视频显示层，使你不用在意底层到底用的是什么声卡什么显卡，是OpenGL还是DirectShow来，SDL会自动识别并调用。你只需要把原始的音频、视频交给SDL去显示就可以了。
* ffplay 就是用 ffmpeg 把文件解码成原始音视频，然后交给SDL做了显示。

