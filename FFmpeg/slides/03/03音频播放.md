## 目标
* 解码视频文件，把声音播放出来，就像播放器一样
* 代码量：220行，核心代码100行

## 回顾
* 因为 FFmpeg 和 SDL 表示原始像素数据（YUV）的方法不同
* 并且因为 FFmpeg 解码得到的 YUV 像素格式不确定
* 所以我们需要用 FFmpeg 的 `sws_scale()` 函数把 FFmpeg 的 YUV 格式转换成 SDL 想要的格式
* sws_scale() 的几个参数：
	* SwsContext： 说明源和目的图像的宽高、格式
	* `const uint8_t *const srcSlice[]`： slice 就是装着各个 plane 的指针的数组，AVFrame里的data就是
	* `const int srcStride[]` ： stride = width + padding，srcStride[]就是装着每个 plane 的 stride 的数组，AVFrame里的 linesize 就是
	* `int srcSliceY`：一般设为0即可
	* `int srcSliceH`：slice height，图像的高度，即 AVCodecContext 里的 height
	* `uint8_t *const dst[]`：目标图像的地址，类似 srcSlice[]，这是一个装着各个 plane 的指针的数组。SDL的 SDL_Overlay 里的 pixels 就是。
	* `const int dstStride[]`: 类似 srcStride[]，装着每个 plane 的 stride 的数组。因为 SDL 里用 16bit 的 int 表示每个 plane 的 stride，而 FFmpeg 里用 32bit int 表示，所以这里需要做一下转换。

## SDL 如何播放音频
* SDL代表了音频设备，有自己的buffer
* 当SDL音频设备需要数据的时候会主动去要
* 打开SDL音频设备时，注册了一个callback函数，SDL通过这个函数要数据
* 因为我们不知道音频设备什么时候会向我们要数据，所以不能像播放视频那样在读packet循环里解码并显示
* 我们的读packet循环只能先把读到的音频包放入队列
* 等音频设备向我们要数据的时候，我们再从队列里拿出packet，解成原始音频数据，给音频设备去播放

## 音频也需要先转换成SDL支持的格式
* `swr_convert()`
* `SwrContext *`

* 假设已有函数实现了队列操作：
	* 初始化： `packet_queue_init(PacketQueue *q)`
	* 入队列：`packet_queue_put(PacketQueue *q, AVPacket *pkt)`
	* 出队列：`packet_queue_get(PacketQueue *q, AVPacket *pkt, int block)`